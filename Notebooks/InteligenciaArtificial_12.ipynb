{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <h1>Inteligencia Artificial</h1>\n",
    "    <h1>Manejo de Incertidumbre</h1>\n",
    "    <h1>Probabilidad</h1>\n",
    "    <h1></h1>\n",
    "    <h5>Prof. Wladimir Rodriguez</h5>\n",
    "    <h5>wladimir.rodriguez@outlook.com</h5>\n",
    "    <h5>Departamento de Computación</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incertidumbre\n",
    "\n",
    "- En problemas de búsqueda, el agente tiene un conocimiento perfecto del mundo y su dinámica.\n",
    "- En la mayoría de las aplicaciones, un agente no puede simplemente hacer suposiciones y luego actuar de acuerdo con esas suposiciones\n",
    "- El conocimiento es incierto:\n",
    "    - Debe considerar múltiples hipótesis\n",
    "    - Debe actualizar las creencias sobre qué hipótesis son probables dadas observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Midiendo la incertidumbre. \n",
    "\n",
    "- La probabilidad es una forma de medir la incertidumbre.\n",
    "- Asignamos un número entre 0 y 1 a las hipótesis:\n",
    "    - 0 significa absolutamente seguro de que la afirmación es falsa \n",
    "    - 1 significa absolutamente seguro de que la afirmación es verdadera \n",
    "    - Los valores intermedios significan más o menos cierto\n",
    "- La probabilidad es una medida de incertidumbre, no de verdad\n",
    "    - Una declaración con probabilidad .75 no es \"mayormente cierta\"\n",
    "    - Más bien, creemos que es más probable que sea cierto que no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilidad\n",
    "\n",
    "En 1814, Pierre-Simon Laplace escribió:\n",
    "\n",
    ">La probabilidad ... es, por lo tanto, simplemente una fracción cuyo numerador es el número de casos favorables y cuyo denominador es el número de todos los casos posibles ... cuando nada nos lleva a esperar que alguno de estos casos ocurra más que cualquier otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Laplace realmente lo tenía claro, ¡en aquel entonces! Si desea desenredar un problema de probabilidad, todo lo que tiene que hacer es ser metódico para definir exactamente cuáles son los casos, y luego tener cuidado al contar el número de casos favorables y totales. Comenzaremos a ser metódicos definiendo un vocabulario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- *Experimento*: Una ocurrencia con un resultado incierto que podemos observar.\n",
    "    Por ejemplo, lanzar un dado.\n",
    "- *Resultado*: el resultado de un experimento; un estado particular del mundo. Lo que Laplace llama un \"caso\".\n",
    "    Por ejemplo: 4.\n",
    "- *Espacio muestral*: el conjunto de todos los resultados posibles para el experimento.\n",
    "    Por ejemplo, {1, 2, 3, 4, 5, 6}.\n",
    "- *Evento*: un subconjunto de posibles resultados que juntos tienen alguna propiedad que nos interesa.\n",
    "    Por ejemplo, el evento \"lanzar pares\" es el conjunto de resultados {2, 4, 6}.\n",
    "- *Probabilidad*: como dijo Laplace, la probabilidad de un evento con respecto a un espacio muestral es el número de casos favorables (resultados del espacio muestral que están en el evento) dividido por el número total de casos en el espacio muestral. (Esto supone que todos los resultados en el espacio muestral son igualmente probables). Dado que es una razón, la probabilidad siempre será un número entre 0 (que representa un evento imposible) y 1 (que representa un determinado evento).\n",
    "    Por ejemplo, la probabilidad que una lanzada de dado sea par es 3/6 = 1/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Código para P\n",
    "\n",
    "P es el nombre tradicional para la función de probabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "def P(evento, espacio): \n",
    "    \"La probabilidad de un evento, dado un espacio muestral de resultados equiprobables.\"\n",
    "    return Fraction(len(evento & espacio), len(espacio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo: dados\n",
    "  \n",
    "- Ana tira un dado de seis lados y obtiene el número X\n",
    "    - Pregunta: ¿Cúal es $P(X = 5)$? (la probabilidad de que Ana sacara un $5$)\n",
    "    - Respuesta: $1/6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(1, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = {1, 2, 3, 4, 5, 6}\n",
    "Ana = {5}\n",
    "\n",
    "P(Ana, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ana le dice sinceramente a Luis que sacó un número impar.\n",
    "    - Pregunta: ¿Qué debería creer Luis es la $P(X = 5)$?\n",
    "    - Respuesta: $1/3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraction(1, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = {1, 3, 5}\n",
    "Ana = {5}\n",
    "\n",
    "P(Ana, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ana le dice sinceramente a Irene que sacó un número $\\ge 5$.\n",
    "    - Pregunta: ¿Qué debería creer Greta es la $P(X = 5)$?\n",
    "    - Respuesta: $1/2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "D = {5, 6}\n",
    "Ana = {5}\n",
    "\n",
    "P(Ana, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subjetivo versus Objetivo: La Perspectiva Bayesiana\n",
    "\n",
    "- Las probabilidades pueden ser interpretadas\n",
    "    - como declaraciones objetivas sobre el mundo, o\n",
    "    - como declaraciones subjetivas sobre las creencias de un agente\n",
    "- La visión subjetiva se llama Bayesiana:\n",
    "    - La probabilidad de un evento es una medida de la creencia de un agente sobre de que tan probable es el evento\n",
    "    - Diferentes agentes pueden tener legítimamente diferentes creencias, por lo que pueden asignar legítimamente diferentes probabilidades al mismo evento.\n",
    "    - Solo hay una forma de actualizar esas creencias en respuesta a nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Semántica: Mundos Posibles\n",
    "\n",
    "- Las *Variables Aleatorias* toman valores de un dominio.\n",
    "    - Las escribiremos como letras mayúsculas (por ejemplo, X, Y, D, etc.)\n",
    "- Un mundo posible es una asignación completa de valores a variables\n",
    "- Una medida de probabilidad es una función $P: \\Omega \\to R$ sobre mundos posibles $ω$ que satisfacen:\n",
    "    1. $\\sum_{w \\in \\Omega}P(w)=1$ \n",
    "    2. $P(w) \\ge 0\\;\\forall w \\in \\Omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Proposición \n",
    "\n",
    "- Una proposición primitiva es una expresión de igualdad o desigualdad.\n",
    "    - Por ejemplo, $X = 5$ o $X \\ge 4$\n",
    "- Una proposición se construye a partir de otras proposiciones utilizando conectores lógicos.\n",
    "    - Por ejemplo, ($X = 1 \\lor X = 3 \\lor X = 5$)\n",
    "- La probabilidad de una proposición es la suma de las probabilidades de los mundos posibles en los que esa proposición es verdadera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$P(\\alpha)=\\sum_{w:w\\models \\alpha}P(w)$$\n",
    "\n",
    "- $w:w\\models \\alpha$ significa \"$\\alpha$ es cierta en $w$\"\n",
    "- Por lo tanto\n",
    "$$P(\\alpha \\lor \\beta) \\ge P(\\alpha) \\\\\n",
    "P(\\alpha \\land \\beta) \\le P(\\alpha) \\\\\n",
    "P(\\neg \\alpha) = 1 - P(\\alpha)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribuciones Conjuntas\n",
    "\n",
    "- En nuestro ejemplo de dados, había una sola variable aleatoria\n",
    "- Por lo general, queremos pensar en las interacciones de múltiples variables aleatorias\n",
    "\n",
    "- Una distribución conjunta asigna una probabilidad a cada asignación completa de valores a variables\n",
    "    - Por ejemplo, $P (X = 1, Y = 5)$. Equivalente a $P (X = 1 \\land Y = 5)$\n",
    "    - Puede ver esto como otra forma de especificar un solo mundo posible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo Distribución Conjunta\n",
    "\n",
    "- ¿Cómo sería un día en Mérida?\n",
    "- Variable aleatorias:\n",
    "    - Clima, con dominio {soleado, nublado}\n",
    "    - Temperatura, con dominio {caliente, templado, frio}\n",
    "- Distribución conjunta:\n",
    "    - $P(Clima, Temperatura)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|Clima|Temperatura|P| \n",
    "|-----|-------|------| \n",
    "|soleado|caliente|0.2| \n",
    "|soleado|templada|0.3|\n",
    "|soleado|fria|0.25|\n",
    "|nublado|caleinte|0.05|\n",
    "|nublado|templada|0.1|\n",
    "|nublado|fria|0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribución Marginal\n",
    "\n",
    "- La marginación es la utilización de una distribución conjunta $P(X_1, \\cdots, X_m, \\cdots, X_n)$ para calcular una distribución sobre un número menor de variables $P(X_1, \\cdots, Xm)$\n",
    "- La distribución más pequeña se llama distribución marginal de sus variables.\n",
    "- Calculamos la distribución marginal sumando las otras variables\n",
    "$$P(X, Y) = \\sum_{z \\in dom(Z)} P(X, Y, Z=z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pregunta:\n",
    "\n",
    "- ¿Cuál es la distribución marginal del clima?\n",
    "\n",
    "$P(soleado) = 0.75$\n",
    "\n",
    "|Clima|Temperatura|P| \n",
    "|-----|-------|------| \n",
    "|soleado|caliente|0.2| \n",
    "|soleado|templada|0.3|\n",
    "|soleado|fria|0.25|\n",
    "|       |    |0.75|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$P(nublado) = 0.25$\n",
    "\n",
    "|Clima|Temperatura|P| \n",
    "|-----|-------|------| \n",
    "|nublado|caliente|0.05| \n",
    "|nublado|templada|0.1|\n",
    "|nublado|fria|0.1|\n",
    "|       |    |0.25|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad condicional\n",
    "\n",
    "- Los agentes deben poder actualizar sus creencias basándose en nuevas observaciones\n",
    "- Este proceso se llama condicionamiento\n",
    "- Escribimos $P (h | e)$ para denotar \"probabilidad de hipótesis $h$ dado que hemos observado evidencia $e$\"\n",
    "    - $P (h | e)$ es la probabilidad de $h$ condicional en $e$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semántica de probabilidad condicional\n",
    "- La evidencia $e$ nos permite descartar todos los mundos que son incompatibles con $e$\n",
    "    - Por ejemplo, si observo que el clima es soleado, ya no debería asignar ninguna probabilidad a los mundos en los que está nublado\n",
    "    - Necesitamos normalizar las probabilidades de los mundos restantes para asegurar que las probabilidades de los mundos posibles sumen 1\n",
    "    \n",
    "\\begin{equation}\n",
    "  P(w|e)=\\begin{cases}\n",
    "    \\frac{1}{P(e)} \\times P(w), & \\text{si $w \\models e$}.\\\\\n",
    "    0, & \\text{otherwise}.\n",
    "  \\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Probabilidad Condicional\n",
    "\n",
    "- Mi creencia marginal inicial sobre el clima fue:\n",
    "    - $P(Clima = nublado) = 0.25$\n",
    "- Supongamos que observo que la temperatura es templada.\n",
    "    - Pregunta: ¿Qué debería creer ahora sobre el clima?\n",
    "    - Respuesta: $P(nublado) = .1/.3 = .33$\n",
    "1. Descarta mundos incompatibles\n",
    "2. Normalizar las probabilidades restantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Clima|Temperatura|P| \n",
    "|-----|-------|------| \n",
    "|~~soleado~~|~~caliente~~|~~0.2~~| \n",
    "|soleado|templada|0.3|\n",
    "|~~soleado~~|~~fria~~|~~0.25~~|\n",
    "|~~nublado~~|~~caleinte~~|~~0.05~~|\n",
    "|nublado|templada|0.1|\n",
    "|~~nublado~~|~~fria~~|~~0.1~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regla de la Cadena\n",
    "\n",
    "- **Definición**: Probabilidad Condicional\n",
    "\n",
    "$$P(h|e)=\\frac{P(h,e)}{P(e)}$$\n",
    "\n",
    "- Podemos ejecutar esto a la inversa para obtener:\n",
    "\n",
    "$$P(h, e)=P(h|e)\\times P(e)$$\n",
    "\n",
    "- **Definición**: Regla de la Cadena\n",
    "\n",
    "$$P(\\alpha_1, \\cdots, \\alpha_n)=P(\\alpha_1)\\times P(\\alpha_2 | \\alpha_1)\\times \\cdots \\times P(\\alpha_n | \\alpha_1, \\cdots, \\alpha_{n-1} ) \\\\\n",
    "= \\prod_{i=1}^{n} P(\\alpha_i | \\alpha_1, \\cdots, \\alpha_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regla de Bayes\n",
    "\n",
    "- De la Regla de la Cadena, tenemos\n",
    "\n",
    "$$P(h|e)=P(h|e)P(e) \\\\\n",
    "= P(e|h)P(h)$$\n",
    "\n",
    "- A menudo, $P(e|h)$ es más facíl de calcular qie $P(h|e)$.\n",
    "\n",
    "- Regla de Bayes:\n",
    "$$P(h|e) = \\frac{P(e|h)P(h)}{P(e)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $h$ se le denomina la hipótesis y a $e$ se le denomina la evidencia.\n",
    "- $P(h)$  Probabilidad de que la hipótesis `h` sea cierta o probabilidad a priori de la hipótesis `h`.\n",
    "- $P(e)$  Probabilidad de que recibamos la evidencia `e` o probabilidad a priori de la evidencia `e`.\n",
    "- $P(e|h)$  Probabilidad de observar la evidencia `e`, cuando se cumple la hipótesis `h` o probabilidad a posteriori de la evidencia `e`.\n",
    "- $P(h|e)$  Probabilidad de que se cumpla la hipótesis `h`, dado que se ha obtenido la evidencia `e`, o probabilidad a posteriori de la hipótesis `h`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que podemos reescribir el Teorema de Bayes como:\n",
    "\n",
    "$$Probabilidad\\ posterior\\ hipótesis = \\frac{(Verosimilitud)\\times (Probabilidad\\ previa\\ hipótesis)}{Probabilidad\\ previa\\ evidencia}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo para entender mejor el teorema de Bayes.\n",
    "\n",
    "Supongamos que usted tiene que sacar una sola carta de una baraja estándar de 52 cartas. Ahora la probabilidad de que la carta sea una Reina es $P(Reina) = \\frac{4}{52} = \\frac{1}{13}$. Si se le da evidencia de que la carta que ha escogido es una carta con una persona, la probabilidad posterior $P(Reina | Persona)$ se puede calcular usando el teorema de Bayes como sigue:\n",
    "\n",
    "$$P(Reina|Persona) = \\frac{P(Persona|Reina)\\times P(Reina)}{P(Persona)}$$\n",
    "\n",
    "Ahora $P (Persona | Reina) = 1$ porque dada que la carta es una reina, es definitivamente una carta de una persona. Ya hemos calculado $P(Reina)$. El único valor que queda para calcular es $P(Persona)$, que es igual a $\\frac {3} {13}$ ya que hay tres cartas de personas para cada palo en una baraja. Por lo tanto,\n",
    "\n",
    "$$P(Reina|Persona) = 1 \\times \\frac{1}{13}\\times \\frac{13}{3}=\\frac{1}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Bayesianas\n",
    "\n",
    "- Las redes bayesianas (o redes de creencia) constituyen una manera práctica y compacta de representar el conocimiento incierto, basada en esta idea\n",
    "- Una red bayesiana es un grafo dirigido acíclico que consta de:\n",
    "    - Un conjunto de nodos, uno por cada variable aleatoria del “mundo”\n",
    "    - Un conjunto de arcos dirigidos que conectan los nodos; si hay un arco de $X$ a $Y$ decimos que $X$ es un padre de $Y$ ($padres(X)$ denota el conjunto de variables aleatorías que son padres de $X$)\n",
    "    - Cada nodo $X_i$ contiene la distribución de probabilidad condicional $P(X_i|padres(X_i))$\n",
    "- Intuitivamente, en una red bayesiana una arco entre $X$ e $Y$ significa una influencia directa de $X$ sobre $Y$\n",
    "    - Es tarea del experto en el dominio el decidir las relaciones de dependencia directa (es decir, la topología de la red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de red bayesiana (Russell y Norvig)\n",
    "\n",
    "![](../figuras/redes_bayesianas_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones sobre el ejemplo\n",
    "\n",
    "- La topología de la red anterior nos expresa que:\n",
    "    - *Caries* es una causa directa de *Dolor* y *Huecos*\n",
    "    - *Dolor* y *Huecos* son condicionalmente independientes dada *Caries*\n",
    "    - Tiempo es independiente de las restantes variables\n",
    "- No es necesario dar la probabilidad de las negaciones de *caries*, *dolor*, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otro ejemplo (Pearl, 1990):\n",
    "\n",
    "- Tenemos una alarma antirrobo instalada en una casa\n",
    "    - La alarma se activa normalmente con la presencia de ladrones\n",
    "    -Pero también cuando ocurren pequeños temblores de tierra\n",
    "- Tenemos dos vecinos en la casa, Juan y María, que han prometido llamar a la policía si oyen la alarma\n",
    "    - Juan y María podrían no llamar aunque la alarma sonara: por tener música muy alta en su casa, por ejemplo\n",
    "    - Incluso podrían llamar aunque no hubiera sonado: por confundirla con un teléfono, por ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red bayesiana para el ejemplo de la alarma\n",
    "\n",
    "![](../figuras/redes_bayesianas_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones sobre el ejemplo\n",
    "\n",
    "- La topología de la red nos expresa que:\n",
    "    - *Robo* y *Terremoto* son causas directas para *Alarma*\n",
    "    - También, *Robo* y *Terremoto* son causas para *Juanllama* y para *Mariallama*, pero esa influencia sólo se produce a través de Alarma: ni Juan ni María detectan directamente el robo ni los pequeños temblores de tierra\n",
    "    - En la red no se hace referencia directa, por ejemplo, a las causas por las cuales María podría no oír la alarma: éstas están implícitas en la tabla de probabilidades $P(Mariallama|Alarma)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un tercer ejemplo (Charniak, 1991):\n",
    "\n",
    "- Supongamos que quiero saber si alguien de mi familia está en casa, basándome en la siguiente información\n",
    "    - Si mi esposa sale de casa, usualmente (pero no siempre) enciende la luz de la entrada\n",
    "    - Hay otras ocasiones en las que también enciende la luz de la entrada\n",
    "    - Si no hay nadie en casa, el perro está fuera\n",
    "    - Si el perro tiene problemas intestinales, también se deja fuera\n",
    "    - Si el perro está fuera, oigo sus ladridos\n",
    "    - Podría oír ladridos y pensar que son de mi perro aunque no fuera así\n",
    "- Variables aleatorias (booleanas) en este problema:\n",
    "    - *Fuera* (nadie en casa), *Luz* (luz en la entrada), *Perro* (perro fuera), *Inst* (problemas intestinales en el perro) y *Oigo* (oigo al perro ladrar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red bayesiana para el ejemplo de la familia fuera de casa\n",
    "\n",
    "![](../figuras/redes_bayesianas_3.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
